{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torchcodec"
      ],
      "metadata": {
        "id": "0b4slx3U9awB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os, random, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "\n",
        "CSV_PATH = Path(\"/content/drive/MyDrive/deep_learning/combined_openmic_and_synth.csv\")\n",
        "\n",
        "OPENMIC_LOCAL = \"/content/drive/MyDrive/openmic-2018-2\"\n",
        "SYNTH_LOCAL   = \"/content/drive/MyDrive/deep_learning/sentetik-dataset\"\n",
        "\n",
        "W_CBAM   = \"/content/drive/MyDrive/model_weights/finetuning/cbam_openmic_plus_synth_best.pth\"\n",
        "W_MSCRNN = \"/content/drive/MyDrive/model_weights/finetuning/mscrnn_openmic_plus_synth_best.pth\"\n",
        "W_PASST  = \"/content/drive/MyDrive/model_weights/finetuning/passt_openmic_plus_synth_best.pth\"\n",
        "\n",
        "for p in [CSV_PATH, Path(W_CBAM), Path(W_MSCRNN), Path(W_PASST)]:\n",
        "    print(p, \"exists?\", p.exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXKiuZIyq4vw",
        "outputId": "74eaf3bc-34a1-49a3-e3e2-aa2f63e4d656"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "DEVICE: cuda\n",
            "/content/drive/MyDrive/deep_learning/combined_openmic_and_synth.csv exists? True\n",
            "/content/drive/MyDrive/model_weights/finetuning/cbam_openmic_plus_synth_best.pth exists? True\n",
            "/content/drive/MyDrive/model_weights/finetuning/mscrnn_openmic_plus_synth_best.pth exists? True\n",
            "/content/drive/MyDrive/model_weights/finetuning/passt_openmic_plus_synth_best.pth exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "\n",
        "df[\"path\"] = (\n",
        "    df[\"path\"]\n",
        "      .str.replace(\"/content/drive/MyDrive/openmic-2018-2\", OPENMIC_LOCAL, regex=False)\n",
        "      .str.replace(\"/content/drive/MyDrive/deep_learning/sentetik-dataset\", SYNTH_LOCAL, regex=False)\n",
        ")\n",
        "\n",
        "sample = df.sample(500, random_state=0)\n",
        "missing = sum(not Path(p).exists() for p in sample[\"path\"])\n",
        "print(\"Missing paths in sample(500):\", missing)\n",
        "print(df[\"source\"].value_counts())\n",
        "print(\"Columns sample:\", df.columns[:20].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv5WGlHCq8zf",
        "outputId": "6ec05bef-c29c-42e0-d052-fa438da157b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing paths in sample(500): 0\n",
            "source\n",
            "openmic      20000\n",
            "synthetic     2200\n",
            "Name: count, dtype: int64\n",
            "Columns sample: ['source', 'path', 'filename', 'polyphony', 'chosen_families', 'y_accordion', 'y_banjo', 'y_bass', 'y_cello', 'y_clarinet', 'y_cymbals', 'y_drums', 'y_flute', 'y_guitar', 'y_mallet_percussion', 'y_mandolin', 'y_organ', 'y_piano', 'y_saxophone', 'y_synthesizer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TAGS = [\n",
        "    \"accordion\",\"banjo\",\"bass\",\"cello\",\"clarinet\",\"cymbals\",\"drums\",\"flute\",\"guitar\",\n",
        "    \"mallet_percussion\",\"mandolin\",\"organ\",\"piano\",\"saxophone\",\"synthesizer\",\n",
        "    \"trombone\",\"trumpet\",\"ukulele\",\"violin\",\"voice\"\n",
        "]\n",
        "\n",
        "Y_COLS = [f\"y_{t}\" for t in TAGS]\n",
        "M_COLS = [f\"m_{t}\" for t in TAGS]\n",
        "\n",
        "assert all(c in df.columns for c in Y_COLS), \"Missing some y_* columns\"\n",
        "assert all(c in df.columns for c in M_COLS), \"Missing some m_* columns\"\n",
        "\n",
        "df[Y_COLS] = df[Y_COLS].astype(np.float32)\n",
        "df[M_COLS] = df[M_COLS].astype(np.float32)\n",
        "\n",
        "print(\"OK: labels ready\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rHXBwvQq9HS",
        "outputId": "7e6edf11-443d-4917-dd0a-b373efc81a49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: labels ready\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "open_df  = df[df[\"source\"]==\"openmic\"].reset_index(drop=True)\n",
        "synth_df = df[df[\"source\"]==\"synthetic\"].reset_index(drop=True)\n",
        "\n",
        "train_open, temp_open = train_test_split(open_df, test_size=0.2, random_state=SEED)\n",
        "val_open, test_open   = train_test_split(temp_open, test_size=0.5, random_state=SEED)\n",
        "\n",
        "train_df = pd.concat([train_open, synth_df], ignore_index=True).reset_index(drop=True)\n",
        "val_df   = val_open.reset_index(drop=True)\n",
        "test_df  = test_open.reset_index(drop=True)\n",
        "\n",
        "print(\"train:\", len(train_df), \"val:\", len(val_df), \"test:\", len(test_df))\n",
        "print(\"val sources:\\n\", val_df[\"source\"].value_counts())\n",
        "print(\"test sources:\\n\", test_df[\"source\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsaegS8jrQO8",
        "outputId": "bdce5a2c-daee-4c8b-8c70-8f01ef5e3fff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 18200 val: 2000 test: 2000\n",
            "val sources:\n",
            " source\n",
            "openmic    2000\n",
            "Name: count, dtype: int64\n",
            "test sources:\n",
            " source\n",
            "openmic    2000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SR = 16000\n",
        "CLIP_S = 10\n",
        "TARGET_LEN = TARGET_SR * CLIP_S\n",
        "\n",
        "def load_audio_mono_16k(path: str):\n",
        "    wav, sr = torchaudio.load(path)  # [C,T]\n",
        "    if wav.size(0) > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)  # [1,T]\n",
        "    if sr != TARGET_SR:\n",
        "        wav = torchaudio.functional.resample(wav, sr, TARGET_SR)\n",
        "    wav = wav.squeeze(0)  # [T]\n",
        "\n",
        "    if wav.numel() < TARGET_LEN:\n",
        "        wav = F.pad(wav, (0, TARGET_LEN - wav.numel()))\n",
        "    else:\n",
        "        wav = wav[:TARGET_LEN]\n",
        "    return wav.unsqueeze(0)  # [1,T]\n",
        "\n",
        "class AudioMultiLabelDataset(Dataset):\n",
        "    def __init__(self, frame: pd.DataFrame):\n",
        "        self.paths = frame[\"path\"].tolist()\n",
        "        self.y = frame[Y_COLS].values.astype(np.float32)\n",
        "        self.m = frame[M_COLS].values.astype(np.float32)\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav = load_audio_mono_16k(self.paths[idx])  # [1,T]\n",
        "        y = torch.from_numpy(self.y[idx])           # [20]\n",
        "        m = torch.from_numpy(self.m[idx])           # [20]\n",
        "        return wav, y, m\n",
        "\n",
        "BATCH = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(AudioMultiLabelDataset(train_df), batch_size=BATCH, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(AudioMultiLabelDataset(val_df), batch_size=BATCH, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(AudioMultiLabelDataset(test_df), batch_size=BATCH, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "wav, y, m = next(iter(val_loader))\n",
        "print(\"wav:\", tuple(wav.shape), \"y:\", tuple(y.shape), \"m:\", tuple(m.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc2VLbjrtZk8",
        "outputId": "c1404cb0-8600-43a2-b176-9847008135ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wav: (64, 1, 160000) y: (64, 20) m: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mel = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=16000,\n",
        "    n_fft=1024,\n",
        "    hop_length=320,\n",
        "    win_length=1024,\n",
        "    n_mels=128,\n",
        "    center=True,\n",
        "    power=2.0\n",
        ").to(DEVICE)\n",
        "\n",
        "def wav_to_logmel(wav_batch: torch.Tensor):\n",
        "    # [B,1,T] -> [B,128,TT]\n",
        "    x = wav_batch.squeeze(1)         # [B,T]\n",
        "    M = mel(x)                       # [B,128,TT]\n",
        "    M = torch.log(M + 1e-6)\n",
        "    M = torch.nan_to_num(M, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    mean = M.mean(dim=(1,2), keepdim=True)\n",
        "    std  = M.std(dim=(1,2), keepdim=True).clamp_min(1e-6)\n",
        "    return (M - mean) / std\n"
      ],
      "metadata": {
        "id": "vbluCTPU7MQR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        hidden = channels // reduction\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(channels, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,C,H,W]\n",
        "        avg = x.mean(dim=(2,3))                 # [B,C]\n",
        "        mx  = x.amax(dim=(2,3))                 # [B,C]\n",
        "        att = self.mlp(avg) + self.mlp(mx)      # [B,C]\n",
        "        att = torch.sigmoid(att).unsqueeze(-1).unsqueeze(-1)  # [B,C,1,1]\n",
        "        return x * att\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        pad = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=pad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,C,H,W]\n",
        "        avg = x.mean(dim=1, keepdim=True)     # [B,1,H,W]\n",
        "        mx  = x.amax(dim=1, keepdim=True)     # [B,1,H,W]\n",
        "        att = torch.sigmoid(self.conv(torch.cat([avg, mx], dim=1)))  # [B,1,H,W]\n",
        "        return x * att\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        self.ca = ChannelAttention(channels, reduction=reduction)\n",
        "        self.sa = SpatialAttention(kernel_size=7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ca(x)\n",
        "        x = self.sa(x)\n",
        "        return x\n",
        "\n",
        "def build_cbam_features():\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=3, padding=1),  # idx 0 (matches 0.weight)\n",
        "        nn.ReLU(inplace=True),                       # idx 1\n",
        "        nn.MaxPool2d(2),                             # idx 2\n",
        "        CBAM(32, reduction=8),                       # idx 3 (matches 3.ca..., 3.sa...)\n",
        "        nn.Conv2d(32, 64, kernel_size=3, padding=1), # idx 4 (matches 4.weight)\n",
        "        nn.ReLU(inplace=True),                       # idx 5\n",
        "        nn.MaxPool2d(2),                             # idx 6\n",
        "        CBAM(64, reduction=8),                       # idx 7 (matches 7.ca..., 7.sa...)\n",
        "    )\n",
        "\n",
        "class CBAMTagger(nn.Module):\n",
        "    def __init__(self, features: nn.Module, n_tags: int = 20):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, n_tags)\n",
        "        )\n",
        "\n",
        "    def forward(self, logmel):\n",
        "        x = logmel.unsqueeze(1)   # [B,1,M,T]\n",
        "        x = self.features(x)      # [B,64,*,*]\n",
        "        x = self.pool(x)          # [B,64,1,1]\n",
        "        return self.head(x)       # [B,20]\n",
        "\n",
        "cbam = CBAMTagger(build_cbam_features(), n_tags=len(TAGS)).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(W_CBAM, map_location=\"cpu\")\n",
        "\n",
        "if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "    sd = ckpt[\"model_state_dict\"]\n",
        "else:\n",
        "    sd = ckpt  # already a plain state_dict\n",
        "\n",
        "# If trained with DataParallel, remove \"module.\" prefix\n",
        "sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
        "\n",
        "missing, unexpected = cbam.load_state_dict(sd, strict=True)\n",
        "print(\"Loaded. Missing:\", missing, \"Unexpected:\", unexpected)\n",
        "\n",
        "cbam.eval()\n",
        "print(\"CBAM loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f58g1PJJ7WgE",
        "outputId": "86486382-bb2c-40d9-ada9-9e2acf3dbaf5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded. Missing: [] Unexpected: []\n",
            "CBAM loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiScaleConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=32):\n",
        "        super().__init__()\n",
        "        self.b1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
        "        self.b2 = nn.Conv2d(in_ch, out_ch, kernel_size=5, padding=2)\n",
        "        self.b3 = nn.Conv2d(in_ch, out_ch, kernel_size=7, padding=3)\n",
        "        self.bn = nn.BatchNorm2d(out_ch*3)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = torch.cat([self.b1(x), self.b2(x), self.b3(x)], dim=1)\n",
        "        y = self.act(self.bn(y))\n",
        "        return self.pool(y)\n",
        "\n",
        "class MSCRNN(nn.Module):\n",
        "    def __init__(self, n_tags=20, base=32, rnn_hidden=256, rnn_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.ms1 = MultiScaleConvBlock(1, base)\n",
        "        self.ms2 = MultiScaleConvBlock(base*3, base)\n",
        "        self.ms3 = MultiScaleConvBlock(base*3, base)\n",
        "        self.drop2d = nn.Dropout2d(dropout)\n",
        "\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=base*3,\n",
        "            hidden_size=rnn_hidden,\n",
        "            num_layers=rnn_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if rnn_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "        self.attn = nn.Linear(rnn_hidden*2, 1)\n",
        "        self.fc = nn.Linear(rnn_hidden*2, n_tags)\n",
        "\n",
        "    def forward(self, logmel):\n",
        "        x = logmel.unsqueeze(1)  # [B,1,F,T]\n",
        "        x = self.drop2d(self.ms1(x))\n",
        "        x = self.drop2d(self.ms2(x))\n",
        "        x = self.drop2d(self.ms3(x))\n",
        "\n",
        "        x = x.mean(dim=2)        # [B,C,T]\n",
        "        x = x.transpose(1,2)     # [B,T,C]\n",
        "        x, _ = self.rnn(x)       # [B,T,2H]\n",
        "\n",
        "        a = torch.softmax(self.attn(x), dim=1)  # [B,T,1]\n",
        "        z = (a * x).sum(dim=1)                  # [B,2H]\n",
        "        return self.fc(z)                       # [B,20]\n",
        "\n",
        "mscrnn = MSCRNN(n_tags=len(TAGS)).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(W_MSCRNN, map_location=\"cpu\")\n",
        "\n",
        "# checkpoint -> actual state_dict\n",
        "if isinstance(ckpt, dict) and \"model\" in ckpt:\n",
        "    sd = ckpt[\"model\"]\n",
        "elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "    sd = ckpt[\"model_state_dict\"]\n",
        "else:\n",
        "    sd = ckpt\n",
        "\n",
        "# common prefix cleanup (DataParallel)\n",
        "sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
        "\n",
        "missing, unexpected = mscrnn.load_state_dict(sd, strict=True)\n",
        "print(\"Loaded. Missing:\", missing, \"Unexpected:\", unexpected)\n",
        "\n",
        "mscrnn.eval()\n",
        "print(\"MS-CRNN loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W5XbD5C7XD_",
        "outputId": "7897f797-b751-4291-fd90-bcafaadf210e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded. Missing: [] Unexpected: []\n",
            "MS-CRNN loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install hear21passt\n",
        "\n",
        "from hear21passt.base import get_basic_model, get_model_passt\n",
        "\n",
        "passt = get_basic_model(mode=\"logits\")\n",
        "passt.net = get_model_passt(arch=\"passt_s_swa_p16_128_ap476\", n_classes=len(TAGS))\n",
        "passt.load_state_dict(torch.load(W_PASST, map_location=\"cpu\"))\n",
        "\n",
        "ckpt = torch.load(W_PASST, map_location=\"cpu\")\n",
        "\n",
        "if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "    sd = ckpt[\"model_state_dict\"]\n",
        "elif isinstance(ckpt, dict) and \"model\" in ckpt:\n",
        "    sd = ckpt[\"model\"]\n",
        "else:\n",
        "    sd = ckpt\n",
        "\n",
        "sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
        "\n",
        "missing, unexpected = passt.load_state_dict(sd, strict=True)\n",
        "print(\"Loaded. Missing:\", missing, \"Unexpected:\", unexpected)\n",
        "\n",
        "passt.to(DEVICE).eval()\n",
        "print(\"PaSST loaded.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yGeV1QWS7eb2",
        "outputId": "a0bd86fb-43c6-41f8-aa55-8f9407bda0b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: FMAX is None setting to 15000 \n",
            "\n",
            "\n",
            " Loading PASST TRAINED ON AUDISET \n",
            "\n",
            "\n",
            "PaSST(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (pre_logits): Identity()\n",
            "  (head): Sequential(\n",
            "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=768, out_features=527, bias=True)\n",
            "  )\n",
            "  (head_dist): Linear(in_features=768, out_features=527, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            " Loading PASST TRAINED ON AUDISET \n",
            "\n",
            "\n",
            "PaSST(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (pre_logits): Identity()\n",
            "  (head): Sequential(\n",
            "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=768, out_features=20, bias=True)\n",
            "  )\n",
            "  (head_dist): Linear(in_features=768, out_features=20, bias=True)\n",
            ")\n",
            "Loaded. Missing: [] Unexpected: []\n",
            "PaSST loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict_probs_cbam_or_ms(model, loader, desc):\n",
        "    all_p, all_y, all_m = [], [], []\n",
        "    for wav, y, m in tqdm(loader, desc=desc):\n",
        "        wav = wav.to(DEVICE, non_blocking=True)  # [B,1,T]\n",
        "        logmel = wav_to_logmel(wav)              # [B,128,TT]\n",
        "        logits = model(logmel)                   # [B,20]\n",
        "        probs = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
        "\n",
        "        all_p.append(probs)\n",
        "        all_y.append(y.numpy().astype(np.float32))\n",
        "        all_m.append(m.numpy().astype(np.float32))\n",
        "\n",
        "    return np.concatenate(all_p), np.concatenate(all_y), np.concatenate(all_m)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_probs_passt(model, loader, desc):\n",
        "    all_p, all_y, all_m = [], [], []\n",
        "    for wav, y, m in tqdm(loader, desc=desc):\n",
        "        wav = wav.to(DEVICE, non_blocking=True)   # [B,1,T]\n",
        "        logmel = wav_to_logmel(wav)               # [B,F,T]\n",
        "        x = logmel.unsqueeze(1)                   # [B,1,F,T]\n",
        "\n",
        "        out = model.net(x)\n",
        "\n",
        "        # PaSST may return (logits, ...) or just logits\n",
        "        logits = out[0] if isinstance(out, (tuple, list)) else out   # [B,20]\n",
        "\n",
        "        probs = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
        "        all_p.append(probs)\n",
        "        all_y.append(y.cpu().numpy().astype(np.float32))\n",
        "        all_m.append(m.cpu().numpy().astype(np.float32))\n",
        "\n",
        "    return np.concatenate(all_p), np.concatenate(all_y), np.concatenate(all_m)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U_Debqcf7f6c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_cbam_val,  y_val,  m_val  = predict_probs_cbam_or_ms(cbam,  val_loader,  \"VAL CBAM\")\n",
        "p_ms_val,    _,      _      = predict_probs_cbam_or_ms(mscrnn,val_loader,  \"VAL MS-CRNN\")\n",
        "\n",
        "\n",
        "p_cbam_test, y_test, m_test = predict_probs_cbam_or_ms(cbam,  test_loader, \"TEST CBAM\")\n",
        "p_ms_test,   _,      _      = predict_probs_cbam_or_ms(mscrnn,test_loader, \"TEST MS-CRNN\")\n",
        "\n",
        "\n",
        "print(\"VAL shapes:\", p_cbam_val.shape, p_ms_val.shape)\n",
        "print(\"TEST shapes:\", p_cbam_test.shape, p_ms_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzcSBmcB7haT",
        "outputId": "ed435a53-280f-4f3f-e491-c44ca2086d5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL CBAM: 100%|| 32/32 [00:25<00:00,  1.28it/s]\n",
            "VAL MS-CRNN: 100%|| 32/32 [00:25<00:00,  1.26it/s]\n",
            "TEST CBAM: 100%|| 32/32 [14:57<00:00, 28.06s/it]\n",
            "TEST MS-CRNN: 100%|| 32/32 [00:24<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL shapes: (2000, 20) (2000, 20)\n",
            "TEST shapes: (2000, 20) (2000, 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_passt_val, _,      _      = predict_probs_passt(passt,     val_loader,  \"VAL PaSST\")\n",
        "p_passt_test,_,      _      = predict_probs_passt(passt,     test_loader, \"TEST PaSST\")\n",
        "\n",
        "print(p_passt_val.shape)\n",
        "print(p_passt_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R91vL-6iF8jM",
        "outputId": "87c53fd6-1374-4626-c294-8263e72fb8fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL PaSST: 100%|| 32/32 [00:44<00:00,  1.39s/it]\n",
            "TEST PaSST: 100%|| 32/32 [00:43<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 20)\n",
            "(2000, 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def macro_f1_at_thr(probs, y_true, m, thr=0.5):\n",
        "    mask = (m > 0.5)\n",
        "    yb = (probs >= thr).astype(np.int32)\n",
        "\n",
        "    f1s = []\n",
        "    for k in range(y_true.shape[1]):\n",
        "        mk = mask[:,k]\n",
        "        if mk.sum() == 0:\n",
        "            continue\n",
        "        yt = y_true[mk,k].astype(np.int32)\n",
        "        yp = yb[mk,k].astype(np.int32)\n",
        "\n",
        "        tp = int(((yp==1)&(yt==1)).sum())\n",
        "        fp = int(((yp==1)&(yt==0)).sum())\n",
        "        fn = int(((yp==0)&(yt==1)).sum())\n",
        "\n",
        "        prec = tp/(tp+fp+1e-9)\n",
        "        rec  = tp/(tp+fn+1e-9)\n",
        "        f1   = 2*prec*rec/(prec+rec+1e-9)\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return float(np.mean(f1s)) if len(f1s) else 0.0\n"
      ],
      "metadata": {
        "id": "EoO4CDlO7jA5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ens_probs(w_cbam, w_ms, w_passt, p1, p2, p3):\n",
        "    return w_cbam*p1 + w_ms*p2 + w_passt*p3\n",
        "\n",
        "best = {\"f1\":-1, \"w\":None, \"thr\":None}\n",
        "\n",
        "cands = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
        "thrs = [0.2,0.3,0.4,0.5]\n",
        "\n",
        "for w_passt in cands:\n",
        "    for w_ms in cands:\n",
        "        w_cbam = 1.0 - w_passt - w_ms\n",
        "        if w_cbam < 0:\n",
        "            continue\n",
        "        p_ens = ens_probs(w_cbam, w_ms, w_passt, p_cbam_val, p_ms_val, p_passt_val)\n",
        "        for thr in thrs:\n",
        "            f1 = macro_f1_at_thr(p_ens, y_val, m_val, thr=thr)\n",
        "            if f1 > best[\"f1\"]:\n",
        "                best = {\"f1\": f1, \"w\": (w_cbam, w_ms, w_passt), \"thr\": thr}\n",
        "\n",
        "print(\"BEST on VAL:\", best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyMNnve7lWW",
        "outputId": "ef3e7f93-8c3c-4019-d655-3adc4264585e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST on VAL: {'f1': 0.4753918985618341, 'w': (0.0, 0.6, 0.4), 'thr': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_cbam, w_ms, w_passt = best[\"w\"]\n",
        "thr = best[\"thr\"]\n",
        "\n",
        "p_ens_test = ens_probs(w_cbam, w_ms, w_passt, p_cbam_test, p_ms_test, p_passt_test)\n",
        "\n",
        "print(\"Ensemble weights:\", best[\"w\"], \"tuned thr:\", thr)\n",
        "print(\"TEST macro-F1@0.2:\", macro_f1_at_thr(p_ens_test, y_test, m_test, thr=0.2))\n",
        "print(\"TEST macro-F1@0.5:\", macro_f1_at_thr(p_ens_test, y_test, m_test, thr=0.5))\n",
        "print(\"TEST macro-F1@tuned:\", macro_f1_at_thr(p_ens_test, y_test, m_test, thr=thr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UEooTL7nbW",
        "outputId": "befce6a9-c8c4-4971-f569-e1783e2bc3b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble weights: (0.0, 0.6, 0.4) tuned thr: 0.5\n",
            "TEST macro-F1@0.2: 0.27883046136217404\n",
            "TEST macro-F1@0.5: 0.4769652414680067\n",
            "TEST macro-F1@tuned: 0.4769652414680067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def per_class_metrics(probs, y_true, m, thr):\n",
        "    rows = []\n",
        "    mask = (m > 0.5)\n",
        "    yb = (probs >= thr).astype(np.int32)\n",
        "\n",
        "    for i, tag in enumerate(TAGS):\n",
        "        mk = mask[:,i]\n",
        "        if mk.sum() == 0:\n",
        "            continue\n",
        "        yt = y_true[mk,i].astype(np.int32)\n",
        "        yp = yb[mk,i].astype(np.int32)\n",
        "\n",
        "        tp = int(((yp==1)&(yt==1)).sum())\n",
        "        fp = int(((yp==1)&(yt==0)).sum())\n",
        "        fn = int(((yp==0)&(yt==1)).sum())\n",
        "\n",
        "        prec = tp/(tp+fp+1e-9)\n",
        "        rec  = tp/(tp+fn+1e-9)\n",
        "        f1   = 2*prec*rec/(prec+rec+1e-9)\n",
        "\n",
        "        rows.append({\n",
        "            \"tag\": tag, \"thr\": thr, \"valid_n\": int(mk.sum()), \"pos_n\": int(yt.sum()),\n",
        "            \"precision\": prec, \"recall\": rec, \"f1\": f1, \"tp\": tp, \"fp\": fp, \"fn\": fn\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
        "\n",
        "df_ens_05 = per_class_metrics(p_ens_test, y_test, m_test, thr=0.5)\n",
        "df_ens_tuned = per_class_metrics(p_ens_test, y_test, m_test, thr=thr)\n",
        "\n",
        "print(\"Top-10 @0.5\")\n",
        "display(df_ens_05.head(10))\n",
        "print(\"Bottom-10 @0.5\")\n",
        "display(df_ens_05.tail(10))\n",
        "\n",
        "OUT1 = Path(\"/content/drive/MyDrive/deep_learning/ensemble_test_per_class_thr0p5.csv\")\n",
        "OUT2 = Path(\"/content/drive/MyDrive/deep_learning/ensemble_test_per_class_thr_tuned.csv\")\n",
        "df_ens_05.to_csv(OUT1, index=False)\n",
        "df_ens_tuned.to_csv(OUT2, index=False)\n",
        "print(\"Saved:\", OUT1)\n",
        "print(\"Saved:\", OUT2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "YOnlrPQf7ozP",
        "outputId": "afd2fb94-f188-474c-c56f-909587ae9908"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 @0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  tag  thr  valid_n  pos_n  precision    recall        f1  \\\n",
              "12              piano  0.5     2000    131   0.737589  0.793893  0.764706   \n",
              "6               drums  0.5     2000    106   0.508671  0.830189  0.630824   \n",
              "5             cymbals  0.5     2000    120   0.550633  0.725000  0.625899   \n",
              "11              organ  0.5     2000     75   0.523364  0.746667  0.615385   \n",
              "8              guitar  0.5     2000    115   0.648936  0.530435  0.583732   \n",
              "18             violin  0.5     2000    132   0.464455  0.742424  0.571429   \n",
              "10           mandolin  0.5     2000     95   0.379487  0.778947  0.510345   \n",
              "9   mallet_percussion  0.5     2000     60   0.508475  0.500000  0.504202   \n",
              "14        synthesizer  0.5     2000    124   0.360902  0.774194  0.492308   \n",
              "1               banjo  0.5     2000     73   0.335404  0.739726  0.461538   \n",
              "\n",
              "     tp   fp  fn  \n",
              "12  104   37  27  \n",
              "6    88   85  18  \n",
              "5    87   71  33  \n",
              "11   56   51  19  \n",
              "8    61   33  54  \n",
              "18   98  113  34  \n",
              "10   74  121  21  \n",
              "9    30   29  30  \n",
              "14   96  170  28  \n",
              "1    54  107  19  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1321a7d-db3e-4caf-8c64-731db43caeca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>thr</th>\n",
              "      <th>valid_n</th>\n",
              "      <th>pos_n</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>piano</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>131</td>\n",
              "      <td>0.737589</td>\n",
              "      <td>0.793893</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>104</td>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>drums</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>106</td>\n",
              "      <td>0.508671</td>\n",
              "      <td>0.830189</td>\n",
              "      <td>0.630824</td>\n",
              "      <td>88</td>\n",
              "      <td>85</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cymbals</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>120</td>\n",
              "      <td>0.550633</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.625899</td>\n",
              "      <td>87</td>\n",
              "      <td>71</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>organ</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>75</td>\n",
              "      <td>0.523364</td>\n",
              "      <td>0.746667</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>56</td>\n",
              "      <td>51</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>guitar</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>115</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.530435</td>\n",
              "      <td>0.583732</td>\n",
              "      <td>61</td>\n",
              "      <td>33</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>violin</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>132</td>\n",
              "      <td>0.464455</td>\n",
              "      <td>0.742424</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>98</td>\n",
              "      <td>113</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>mandolin</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>95</td>\n",
              "      <td>0.379487</td>\n",
              "      <td>0.778947</td>\n",
              "      <td>0.510345</td>\n",
              "      <td>74</td>\n",
              "      <td>121</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mallet_percussion</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>60</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.504202</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>synthesizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>124</td>\n",
              "      <td>0.360902</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>0.492308</td>\n",
              "      <td>96</td>\n",
              "      <td>170</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>banjo</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>73</td>\n",
              "      <td>0.335404</td>\n",
              "      <td>0.739726</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>54</td>\n",
              "      <td>107</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1321a7d-db3e-4caf-8c64-731db43caeca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1321a7d-db3e-4caf-8c64-731db43caeca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1321a7d-db3e-4caf-8c64-731db43caeca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b62f95d-9a1d-4e5b-8f77-6b45e15cc3d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b62f95d-9a1d-4e5b-8f77-6b45e15cc3d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b62f95d-9a1d-4e5b-8f77-6b45e15cc3d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Saved:\\\", OUT2)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"synthesizer\",\n          \"drums\",\n          \"violin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valid_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 60,\n        \"max\": 132,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12652700449639928,\n        \"min\": 0.3354037267059913,\n        \"max\": 0.7375886524770384,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.360902255637741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1104677410491702,\n        \"min\": 0.4999999999916667,\n        \"max\": 0.830188679237451,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7741935483808533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08963433347045162,\n        \"min\": 0.46153846110523045,\n        \"max\": 0.7647058818479943,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4923076918714529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 30,\n        \"max\": 104,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 29,\n        \"max\": 170,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 18,\n        \"max\": 54,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bottom-10 @0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          tag  thr  valid_n  pos_n  precision    recall        f1  tp   fp  fn\n",
              "2        bass  0.5     2000     52   0.412698  0.500000  0.452174  26   37  26\n",
              "16    trumpet  0.5     2000    127   0.334630  0.677165  0.447917  86  171  41\n",
              "3       cello  0.5     2000     92   0.309623  0.804348  0.447130  74  165  18\n",
              "13  saxophone  0.5     2000    110   0.318182  0.700000  0.437500  77  165  33\n",
              "17    ukulele  0.5     2000     76   0.278626  0.960526  0.431953  73  189   3\n",
              "15   trombone  0.5     2000     98   0.239044  0.612245  0.343840  60  191  38\n",
              "19      voice  0.5     2000     89   0.703704  0.213483  0.327586  19    8  70\n",
              "7       flute  0.5     2000     64   0.365385  0.296875  0.327586  19   33  45\n",
              "4    clarinet  0.5     2000     53   0.196809  0.698113  0.307054  37  151  16\n",
              "0   accordion  0.5     2000     44   0.156566  0.704545  0.256198  31  167  13"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3acc09e8-3b0c-486d-b9b7-ce8c44134336\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>thr</th>\n",
              "      <th>valid_n</th>\n",
              "      <th>pos_n</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bass</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>52</td>\n",
              "      <td>0.412698</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.452174</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>trumpet</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>127</td>\n",
              "      <td>0.334630</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.447917</td>\n",
              "      <td>86</td>\n",
              "      <td>171</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cello</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>92</td>\n",
              "      <td>0.309623</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.447130</td>\n",
              "      <td>74</td>\n",
              "      <td>165</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>saxophone</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>110</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>77</td>\n",
              "      <td>165</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ukulele</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>76</td>\n",
              "      <td>0.278626</td>\n",
              "      <td>0.960526</td>\n",
              "      <td>0.431953</td>\n",
              "      <td>73</td>\n",
              "      <td>189</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>trombone</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>98</td>\n",
              "      <td>0.239044</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.343840</td>\n",
              "      <td>60</td>\n",
              "      <td>191</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>voice</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>89</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.213483</td>\n",
              "      <td>0.327586</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>flute</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>64</td>\n",
              "      <td>0.365385</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.327586</td>\n",
              "      <td>19</td>\n",
              "      <td>33</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clarinet</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>53</td>\n",
              "      <td>0.196809</td>\n",
              "      <td>0.698113</td>\n",
              "      <td>0.307054</td>\n",
              "      <td>37</td>\n",
              "      <td>151</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accordion</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>44</td>\n",
              "      <td>0.156566</td>\n",
              "      <td>0.704545</td>\n",
              "      <td>0.256198</td>\n",
              "      <td>31</td>\n",
              "      <td>167</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3acc09e8-3b0c-486d-b9b7-ce8c44134336')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3acc09e8-3b0c-486d-b9b7-ce8c44134336 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3acc09e8-3b0c-486d-b9b7-ce8c44134336');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e387674-8d7d-4187-b4ba-d3820092557d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e387674-8d7d-4187-b4ba-d3820092557d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e387674-8d7d-4187-b4ba-d3820092557d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Saved:\\\", OUT2)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"clarinet\",\n          \"trumpet\",\n          \"trombone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valid_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 44,\n        \"max\": 127,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15166861813639065,\n        \"min\": 0.15656565656486585,\n        \"max\": 0.7037037036776406,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.19680851063725102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22530934688829,\n        \"min\": 0.21348314606501703,\n        \"max\": 0.9605263157768351,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6981132075339979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07283093411509778,\n        \"min\": 0.25619834680780007,\n        \"max\": 0.45217391254018907,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3070539415630585\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 19,\n        \"max\": 86,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71,\n        \"min\": 8,\n        \"max\": 191,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 3,\n        \"max\": 70,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/deep_learning/ensemble_test_per_class_thr0p5.csv\n",
            "Saved: /content/drive/MyDrive/deep_learning/ensemble_test_per_class_thr_tuned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R57a2_fllqFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}